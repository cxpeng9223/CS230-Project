{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from sklearn import feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_time_csv(file_path, iden_str):\n",
    "    \n",
    "    file_counter = 0\n",
    "    for filename in os.listdir(file_path):\n",
    "        if iden_str in filename:\n",
    "            if file_counter == 0:\n",
    "                output_df = pd.read_csv(file_path + '/' + filename, names=['Time', 'Open', 'High', 'Low', 'Close'])\n",
    "            else:\n",
    "                output_df = pd.concat([output_df, pd.read_csv(file_path + '/' + filename)], names=['Time', 'Open', 'High', 'Low', 'Close'])\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    label_df = load_time_csv('Inputs', '_12')\n",
    "    tweet_df = pd.read_csv('Inputs/trumptweet.csv', encoding='latin-1')\n",
    "    label_df['Time']= pd.to_datetime(label_df['Time'])\n",
    "    \n",
    "    label_time_stamps = list(label_df['Time'])\n",
    "    closed_number = list(label_df['Close'])\n",
    "    \n",
    "    label_time_stamps_dt = []\n",
    "    for time in label_time_stamps:\n",
    "        label_time_stamps_dt.append(time.to_pydatetime())\n",
    "    \n",
    "    original_tweet_df = tweet_df[tweet_df['is_retweet'] != True].reset_index()\n",
    "    del original_tweet_df['index']\n",
    "    \n",
    "    time_stamp_dict = {}\n",
    "    \n",
    "    for idx, row in original_tweet_df.iterrows():\n",
    "        if row['created_at'] not in time_stamp_dict:\n",
    "            time_stamp_dict[row['created_at']] = row['text']\n",
    "        else:\n",
    "            time_stamp_dict[row['created_at']] = time_stamp_dict[row['created_at']] + \" \" + row['text']\n",
    "    \n",
    "    \n",
    "    #print(original_tweet_df)\n",
    "    #print(time_stamp_dict)\n",
    "    time_stamps = list(time_stamp_dict.keys())\n",
    "    content = list(time_stamp_dict.values())\n",
    "    \n",
    "    selected_time = []\n",
    "    selected_text = []\n",
    "    \n",
    "    \n",
    "    for idx, time_str in enumerate(time_stamps):\n",
    "        try:\n",
    "            time_stamp = datetime.datetime.strptime(time_str, '%m/%d/%y %H:%M')\n",
    "            if time_stamp in label_time_stamps_dt:\n",
    "                selected_time.append(time_stamp)\n",
    "                selected_text.append(content[idx])\n",
    "                \n",
    "        except TypeError:\n",
    "            #print(time_str)\n",
    "            continue\n",
    "    \n",
    "    vectorizer = feature_extraction.text.CountVectorizer()\n",
    "    X = vectorizer.fit_transform(selected_text)\n",
    "    \n",
    "    \n",
    "    feature_array = X.toarray()\n",
    "    print(len(vectorizer.get_feature_names()))\n",
    "    print(feature_array.shape)\n",
    "    \n",
    "    label_list = []\n",
    "    trend_list = []\n",
    "    \n",
    "    for time in selected_time:\n",
    "        idx = label_time_stamps_dt.index(time)\n",
    "        \n",
    "        if closed_number[idx] >= closed_number[idx+1]:\n",
    "            label_list.append(0)\n",
    "        else:\n",
    "            label_list.append(1)\n",
    "            \n",
    "        trend_list.append(closed_number[idx-10: idx])\n",
    "            \n",
    "    trend_array = np.array(trend_list)\n",
    "    \n",
    "    X_array = np.concatenate((trend_array, feature_array), axis=1)\n",
    "    \n",
    "    total_array = np.concatenate((np.array(label_list).reshape(len(label_list), 1), X_array), axis=1)\n",
    "    \n",
    "    np.savetxt(\"total_array.csv\", total_array, delimiter=\",\", fmt='%f')\n",
    "    print(total_array.shape)\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5969\n",
      "(1859, 5969)\n",
      "(1859, 5980)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
